# Machine Learning Pipeline Recommendation

### Directory Detail:
    .
    ├── model                  
    │   ├── datase_ppl_model.ipynb              # Model for multiple dataset case, with tesing and analysis
    │   └── ppl_instance_model.ipynb            # Model for one dataset case, with tesing and analysis
    └── data
        ├── data_generation.py                  # Run SROM on dataset(s) to generate pipelines
        ├── data_preprocessing.py               # Construct 3D tensors
        ├── data_refining.py                    # Refine raw data
        ├── multiple_datasets
        |   ├── data_visualization 
        |   |   ├── visualization.ipynb         # Visualize clustering
        |   |   └── ... <related_data_files>
        |   └── ...<related_data_files>
        |
        └── one_dataset
            ├── data_visualization 
            |   ├── visualization.ipynb         # Visualize clustering
            |   ├── pipeline_cluster.ipynb      # Visualize pipeline clustering
            |   └── ... <related_data_files>
            └── ...<related_data_files>
All <related_data_files> are uploaded to Box, Link: https://ibm.box.com/s/iosxgrzb7w6061v77h2hh4huxenenmr1

### Requirements:
* Files 'data_generation.py' and 'data_preprocessing.py' need to be run on IBM virtial machine with SROM installed
    * IBM Virtual Machine Setup Instruction: VM_setup.md
    * SROM Installation Instruction: srom_installation.md
* Files 'datase_ppl_model.ipynb' and 'ppl_instance_model.ipynb' need to be run on Colab
* Files 'visualization.ipynb' need to be run on IBM Watson Studio

### Data File Description:
| **Data Filename**                       	| **Data Description**                                                                                                                                                                                                                    	|
|--------------------------------------	|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------	|
| **multiple_datasets**                    	|                                                                                                                                                                                                                                     	|
| ‘data_ppl_acc_finalDF.csv            	| DataFrame of shape (7478, 3)<br>data_df.columns = [‘dataset_name’, ‘pipeline_name’, ‘accuracy’]                                                                                                                                     	|
| ‘datasets_mapping.pickle’            	| list([str(‘dataset_name’)])     length = 121 (= number of datasets)                                                                                                                                                                 	|
| ‘est_info.pickle’                    	| {‘dataset_name’: list([pipelines_detail_info])}<br>Store the pipelines detail information for each dataset generated by srom AutoClassification (121 classification datasets)                                                       	|
| ‘full_sim_matrix.pickle’             	| numpy.array((datasetID, datasetID))<br>Store the similarity matrix for multiple datasets, each cell is CCA score                                                                                                                    	|
| ‘num_ppl_data.pickle’                	| {‘dataset_name’: (num_pipelines, num_instances)}<br>For each dataset, store number of pipelines generated by srom AutoClassification, and the number of instances in this dataset                                                   	|
| ‘ppl_dataset2d.pickle’               	| numpy.array((pipelineID, datasetID))<br>Each cell is the accuracy or numpy.NaN; shape = (313, 121)                                                                                                                                  	|
| ‘pplID_mapping_df.csv’               	| DataFrame of shape (121, 313)<br>df.iloc[datasetID, pipelineID] = correspondPipline / NaN                                                                                                                                           	|
| ‘tensor.pickle’                      	| {‘dataset_name’: numpy.array((pipelineID, instanceID))}<br>Store the result when running srom AutoClassification (121 classification datasets), dictionary values are 2D binary tensor                                              	|
| ‘tensor3d.pickle’                    	| numpy.array((datasetID, pipelineID, instanceID))<br>Construct the 3D tensor from the files ‘tensor121.pickle’ and ‘est_info121.pickle’, where each cell is 0/1/numpy.NaN indicate true classification, false classification and NaN 	|
| **multiple_datasets/data_visualization** 	|                                                                                                                                                                                                                                     	|
| ‘filtered_pplID.csv’                 	| DataFrame: data_df.columns = [‘dataset_id’, ‘pipeline_id’, ‘accuracy’]                                                                                                                                                              	|
| ‘nmf_pu.pickle’                      	| numpy.array((datasetID, num_topic=2))<br>pu matrix result from nmf decomposition of ‘ppl_dataset2d_121.pickle’ numpy array with NaN and low occurrence pipelineID removed [shape = (121, 2)]                                        	|
| ‘nmf_qi.pickle’                      	| numpy.array((pipelineID, num_topic=2))<br>qi matrix result from nmf decomposition of ‘ppl_dataset2d_121.pickle’ numpy array with NaN and low occurrence pipelineID removed [shape = (256, 2)]                                       	|
| ‘removed_pplID.csv’                  	| DataFrame of shape (97, 3); Cols: ‘dataset_id’, ‘pipeline_id’, ‘accuracy’<br>Removed rows from ‘ppl_dataset2d_121.pickle’ with low pplID occurrence                                                                                 	|
| **one_datasets**                         	|                                                                                                                                                                                                                                     	|
| ‘instance_feature.pickle’            	| numpy.array((#instance, #feature=3))<br>Use for calculating the similarity of instances in the dataset                                                                                                                              	|
| ‘ppl_instance_pred01.csv’            	| numpy.array((#pipeline, #instance))<br>where each cell = {0, 1} = {True prediction, False prediction}                                                                                                                               	|
| ‘ppl_instance_pred14.csv’            	| numpy.array((#pipeline, #instance))<br>where each cell = {1, 2, 3, 4} =  {false positive, true negative, false negative, true positive}                                                                                             	|
| **one_dataset/data_visualization**       	|                                                                                                                                                                                                                                     	|
| ‘instance_detail.csv’                	| DataFrame: data_df.columns = [‘Pipeline_Acc, ‘topic0, ‘topic1’]                                                                                                                                                                     	|
| ‘matrix_detail.xlsx’                 	| DataFrame: data_df.columns = [‘Pipeline Detail, ‘Accuracy0, ‘Accuracy1’, ‘Accuracy2’, ‘Accuracy3’] (Contructed from multiple DataFrame)                                                                                             	|

## Data 
* Data Generation
    *  For each dataset run SROM to generate best set of pipelines
    *  Rerun the set of generated pipelines on the test dataset, record the predictions as {0, 1} = {True prediction, False prediction}
* Data Preprocessing
    *  Use generated raw data to construct 3D tensors
* Data Analysis
    *  Visualize data use PCA, NMF, TSNE, etc.
    *  Visualize factors use histogram

## Model Construction
* Fastai Collaborative Filtering
    *  One dataset case: add regularization & instance similarity
    *  Multiple datasets case: add regularization & dataset similarity

## Techniques
* Dataset space: Penn Machine Learning Benchmarks
* Data generation: SROM (AutoClassification)
* Model: Fastai Collaborative Filtering
* Matrix Factorization: PCA, NMF
* Similarity measurement:
    * One dataset: cosine similarity, Euclidean distance
    * Multiple datasets: Canonical Correlation Analysis (CCA) score
* Data visualization: Clustering (TSNE, Dendrogram), Histogram, Linear Regression, Decis
